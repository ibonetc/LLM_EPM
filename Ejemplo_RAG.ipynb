{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ibonetc/LLM_EPM/blob/main/Ejemplo_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7c9da218-2473-43e9-9349-3180ef98f442",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "_QHi113ri-TV",
        "outputId": "22176238-66a2-406e-b2d5-be7ad8f52403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n  Obtaining dependency information for faiss-cpu from https://files.pythonhosted.org/packages/51/b2/4f9abd2b859cef0e2332d3ff032e1973281fac1204fa8da14effc326f528/faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n  Obtaining dependency information for numpy<3.0,>=1.25.0 from https://files.pythonhosted.org/packages/7a/f0/80811e836484262b236c684a75dfc4ba0424bc670e765afaa911468d9f39/numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\nDownloading faiss_cpu-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/27.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n\u001b[2K   \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/27.5 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/27.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n\u001b[2K   \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/27.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/27.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/27.5 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/27.5 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/27.5 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/27.5 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.4/27.5 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m19.3/27.5 MB\u001b[0m \u001b[31m117.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m24.8/27.5 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m161.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/16.3 MB\u001b[0m \u001b[31m163.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/16.3 MB\u001b[0m \u001b[31m162.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m168.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m168.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m168.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, faiss-cpu\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-105f56b9-f97c-4b4e-a763-6b95f8ae6238\n    Can't uninstall 'numpy'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\ndatabricks-feature-engineering 0.6.0 requires numpy<2,>=1.19.2, but you have numpy 2.1.3 which is incompatible.\nlangchain 0.1.20 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\nlangchain-community 0.0.38 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.1.3 which is incompatible.\nscipy 1.11.1 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.3 which is incompatible.\ntensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed faiss-cpu-1.9.0 numpy-2.1.3\n\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "a0f00f17-cbab-493c-9ed5-e0564e788c67",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-eI6ZTF_i-TY"
      },
      "source": [
        "##Crear el conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b0df2e07-1c28-4f7d-9d65-e0a73cf25c27",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "N-JMV8eHi-TZ"
      },
      "outputs": [],
      "source": [
        "document1='''\n",
        "La inteligencia artificial (IA), en el contexto de las ciencias de la computación, es una disciplina y un conjunto de capacidades cognoscitivas e intelectuales expresadas por sistemas informáticos o combinaciones de algoritmos cuyo propósito es la creación de máquinas que imiten la inteligencia humana para realizar tareas, y que pueden mejorar conforme recopilen información.1​2​ Se hizo presente poco después de la Segunda Guerra Mundial con el desarrollo de la «prueba de Turing», mientras que la locución fue acuñada en 1956 por el informático John McCarthy en la Conferencia de Dartmouth.\n",
        "\n",
        "En la actualidad, la inteligencia artificial abarca una gran variedad de subcampos. Éstos van desde áreas de propósito general, aprendizaje y percepción, a otras más específicas como el reconocimiento de voz, el juego de ajedrez, la demostración de teoremas matemáticos, la escritura de poesía y el diagnóstico de enfermedades. La inteligencia artificial sintetiza y automatiza tareas que en principio son intelectuales y, por lo tanto, es potencialmente relevante para cualquier ámbito de actividades intelectuales humanas. En este sentido, es un campo genuinamente universal.\n",
        "\n",
        "La arquitectura de las inteligencias artificiales y los procesos por los cuales aprenden, se mejoran y se implementan en algún área de interés varía según el enfoque de utilidad que se les quiera dar, pero de manera general, estos van desde la ejecución de sencillos algoritmos hasta la interconexión de complejas redes neuronales artificiales que intentan replicar los circuitos neuronales del cerebro humano y que aprenden mediante diferentes modelos de aprendizaje tales como el aprendizaje automático, el aprendizaje por refuerzo, el aprendizaje profundo y el aprendizaje supervisado.\n",
        "\n",
        "Por otro lado, el desarrollo y aplicación de la inteligencia artificial en muchos aspectos de la vida cotidiana también ha propiciado la creación de nuevos campos de estudio como la roboética y la ética de las máquinas que abordan aspectos relacionados con la ética en la inteligencia artificial y que se encargan de analizar cómo los avances en este tipo de tecnologías impactarían en diversos ámbitos de la vida, así como el manejo responsable y ético que se les debería dar a los mismos, además de establecer cuál debería ser la manera correcta de proceder de las máquinas y las reglas que deberían cumplir.\n",
        "\n",
        "En cuanto a su clasificación, tradicionalmente se divide a la inteligencia artificial en inteligencia artificial débil, la cual es la única que existe en la actualidad y que se ocupa de realizar tareas específicas, e inteligencia artificial general, que sería una IA que excediese las capacidades humanas. Algunos expertos creen que si alguna vez se alcanza este nivel, se podría dar lugar a la aparición de una singularidad tecnológica, es decir, una entidad tecnológica superior que se mejoraría a sí misma constantemente, volviéndose incontrolable para los humanos, dando pie a teorías como el basilisco de Roko.\n",
        "\n",
        "Algunas de las inteligencias artificiales más conocidas y utilizadas en la actualidad alrededor del mundo incluyen inteligencia artificial en el campo de la salud, asistentes virtuales como Alexa, el asistente de Google o Siri, traductores automáticos como el traductor de Google y DeepL, sistemas de recomendación como el de la plataforma digital de YouTube, motores de ajedrez y otros juegos como Stockfish y AlphaZero, chatbots como ChatGPT, creadores de arte de inteligencia artificial como Midjourney, Dall-e, Leonardo y Stable Diffusion, e incluso la conducción de vehículos autónomos como Tesla Autopilot.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a9013ffa-e7c9-4a9f-8f2e-7f8d3e839131",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "aP3a3SIri-Ta"
      },
      "outputs": [],
      "source": [
        "document2='''\n",
        "En 2019 la Comisión Mundial de Ética del Conocimiento Científico y la Tecnología (COMEST) de la UNESCO definió la inteligencia artificial como un campo que implica máquinas capaces de imitar determinadas funcionalidades de la inteligencia humana, incluidas características como la percepción, el aprendizaje, el razonamiento, la resolución de problemas, la interacción lingüística e incluso la producción de trabajos creativos.\n",
        "\n",
        "Coloquialmente, la locución «inteligencia artificial» se aplica cuando una máquina imita las funciones «cognitivas» que los humanos asocian como competencias humanas, por ejemplo: «percibir», «razonar», «aprender» y «resolver problemas».8​ Andreas Kaplan y Michael Haenlein definen la inteligencia artificial como «la capacidad de un sistema para interpretar correctamente datos externos, y así aprender y emplear esos conocimientos para lograr tareas y metas concretas a través de la adaptación flexible».9​ A medida que las máquinas se vuelven cada vez más capaces, se elimina de la definición la tecnología que alguna vez se pensó que requería de inteligencia. Marvin Minsky, uno de los ideadores de la IA, hablaba del término inteligencia artificial como una palabra maleta (\"suitcase word\") porque en él se pueden meter una diversidad de elementos.\n",
        "\n",
        "Por ejemplo, el reconocimiento óptico de caracteres ya no se percibe como un ejemplo de la «inteligencia artificial» habiéndose convertido en una tecnología común.12​ Avances tecnológicos todavía clasificados como inteligencia artificial son los sistemas de conducción autónomos o los capaces de jugar ajedrez o Go.\n",
        "\n",
        "La inteligencia artificial es una nueva forma de resolver problemas dentro de los cuales se incluyen los sistemas expertos, el manejo y control de robots y los procesadores, que intenta integrar el conocimiento en tales sistemas, en otras palabras, un sistema inteligente capaz de escribir su propio programa. Un sistema experto definido como una estructura de programación capaz de almacenar y utilizar un conocimiento sobre un área determinada que se traduce en su capacidad de aprendizaje.14​ De igual manera se puede considerar a la IA como la capacidad de las máquinas para usar algoritmos, aprender de los datos y utilizar lo aprendido en la toma de decisiones tal y como lo haría un ser humano.\n",
        "\n",
        "Según Takeyas (2007) la IA es una rama de las ciencias computacionales encargada de estudiar modelos de cómputo capaces de realizar actividades propias de los seres humanos con base en dos de sus características primordiales: el razonamiento y la conducta.​\n",
        "\n",
        "En 1956, John McCarthy acuñó la expresión «inteligencia artificial», y la definió como «la ciencia e ingenio de hacer máquinas inteligentes, especialmente programas de cómputo inteligentes».\n",
        "\n",
        "Grau-Luque contrasta diferentes definiciones desde diversas fuentes y autores, destacando que difieren dependiendo de \"en qué campo específico se usen\".18​Esto lleva al autor a definir «inteligencia artificial» como \"sistemas que llevan a cabo tareas consideradas inteligentes\", para luego asociar conceptos como «aprendizaje» y «razonamiento» con el aprendizaje automático como una subdisciplina de la inteligencia artificial.\n",
        "\n",
        "También existen distintos tipos de percepciones y acciones, que pueden ser obtenidas y producidas, respectivamente, por sensores físicos y sensores mecánicos en máquinas, pulsos eléctricos u ópticos en computadoras, tanto como por entradas y salidas de bits de un software y su entorno software.\n",
        "\n",
        "Varios ejemplos se encuentran en el área de control de sistemas, planificación automática, la capacidad de responder a diagnósticos y a consultas de los consumidores, reconocimiento de escritura, reconocimiento del habla y reconocimiento de patrones. Los sistemas de IA actualmente son parte de la rutina en campos como economía, medicina, ingeniería, el transporte, las comunicaciones y la milicia, y se ha usado en gran variedad de programas informáticos, juegos de estrategia, como ajedrez de computador, y otros videojuegos.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c1d4dbc5-549d-4a5e-8208-fa78b12f1020",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ayORwUCQi-Tb"
      },
      "outputs": [],
      "source": [
        "document3='''\n",
        "Stuart J. Russell y Peter Norvig diferencian varios tipos de inteligencia artificial:\n",
        "\n",
        "Los sistemas que piensan como humanos: Estos sistemas tratan de emular el pensamiento humano; por ejemplo, las redes neuronales artificiales. La automatización de actividades que vinculamos con procesos de pensamiento humano, actividades como la toma de decisiones, resolución de problemas y aprendizaje.\n",
        "Los sistemas que actúan como humanos: Estos sistemas tratan de actuar como humanos; es decir, imitan el comportamiento humano; por ejemplo, la robótica (El estudio de cómo lograr que los computadores realicen tareas que, por el momento, los humanos hacen mejor).\n",
        "Los sistemas que piensan racionalmente: Es decir, con lógica (idealmente), tratan de imitar el pensamiento racional del ser humano; por ejemplo, los sistemas expertos, (el estudio de los cálculos que hacen posible percibir, razonar y actuar).\n",
        "Los sistemas que actúan racionalmente: Tratan de emular de forma racional el comportamiento humano; por ejemplo, los agentes inteligentes, que está relacionado con conductas inteligentes en artefactos.23​\n",
        "Inteligencia artificial generativa\n",
        "Artículo principal: Inteligencia artificial generativa\n",
        "La inteligencia artificial generativa es un tipo de sistema de inteligencia artificial capaz de generar texto, imágenes u otros medios en respuesta a comandos.24​ Los modelos de IA generativa aprenden los patrones y la estructura de sus datos de entrenamiento de entrada y luego generan nuevos datos que tienen características similares.\n",
        "\n",
        "Los sistemas de IA generativa notables incluyen ChatGPT (y su variante Microsoft Copilot), un bot conversacional creado por OpenAI usando sus modelos de lenguaje grande fundacionales GPT-3 y GPT-4;​ y Gemini (anteriormente llamado Bard), un bot conversacional creado por Google usando el modelo de lenguaje Gemini. Otros modelos generativos de IA incluyen sistemas de arte de inteligencia artificial como Stable Diffusion, Midjourney y DALL-E.\n",
        "\n",
        "Inteligencia artificial fuerte\n",
        "Artículo principal: Inteligencia artificial fuerte\n",
        "La Inteligencia artificial fuerte (IGA) es un tipo hipotético de inteligencia artificial que iguala o excede la inteligencia humana promedio.​ Si se hiciera realidad, una IGA podría aprender a realizar cualquier tarea intelectual que los seres humanos o los animales puedan llevar a cabo.​​ Alternativamente, la IGA se ha definido como un sistema autónomo que supera las capacidades humanas en la mayoría de las tareas económicamente valiosas.\n",
        "\n",
        "Algunos sostienen que podría ser posible en años o décadas; otros, que podría tardar un siglo o más; y una minoría cree que quizá nunca se consiga.​ Existe un debate sobre la definición exacta de IGA y sobre si los grandes modelos de lenguaje (LLM) modernos, como el GPT-4, son formas tempranas pero incompletas de IGA.\n",
        "\n",
        "Inteligencia artificial explicable\n",
        "Artículo principal: Inteligencia artificial explicable\n",
        "La inteligencia artificial explicable se refiere a métodos y técnicas en la aplicación de tecnología de inteligencia artificial por los que el ser humano es capaz de comprender las decisiones y predicciones realizadas por la inteligencia artificial.\n",
        "\n",
        "Inteligencia artificial amigable\n",
        "Artículo principal: Inteligencia artificial amigable\n",
        "La inteligencia artificial amigable es una IA fuerte e hipotética que puede tener un efecto positivo más que uno negativo sobre la humanidad. 'Amigable' es usado en este contexto como terminología técnica y escoge agentes que son seguros y útiles, no necesariamente aquellos que son \"amigables\" en el sentido coloquial. El concepto es invocado principalmente en el contexto de discusiones de agentes artificiales de auto-mejora recursiva que rápidamente explota en inteligencia, con el argumento de que esta tecnología hipotética pudiera tener una larga, rápida y difícil tarea de controlar el impacto en la sociedad humana.\n",
        "\n",
        "Inteligencia artificial multimodal\n",
        "Artículo principal: Inteligencia artificial multimodal\n",
        "La inteligencia artificial multimodal es un tipo de inteligencia artificial que puede procesar e integrar datos de diferentes modalidades, como texto, imágenes, audio y video, para obtener una comprensión más completa y contextualizada de una situación. La inteligencia artificial multimodal se inspira en la forma en que los humanos usan varios sentidos para percibir e interactuar con el mundo, y ofrece una forma más natural e intuitiva de comunicarse con la tecnología.\n",
        "\n",
        "Inteligencia artificial cuántica\n",
        "Artículo principal: Inteligencia Artificial Cuántica\n",
        "La inteligencia artificial Cuántica es un campo interdisciplinar que se enfoca en construir algoritmos cuánticos para mejorar las tareas computacionales dentro de la IA, incluyendo subcampos como el aprendizaje automático.​ Existen evidencias que muestran una posible ventaja cuadrática cuántica en operaciones fundamentales de la IA.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c25ad7f0-4eff-437a-b216-2366bdf659a9",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "xpYD8w_Yi-Tb"
      },
      "outputs": [],
      "source": [
        "documents = []\n",
        "documents.append(document1)\n",
        "documents.append(document2)\n",
        "documents.append(document3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "47b243af-66ad-4003-b14a-b8163cd782ed",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-6oCgOlSi-Tc"
      },
      "source": [
        "## Token de HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "db4c4515-7ce8-4c03-bf18-e69930ab34e4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GaUk39C0i-Tc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "token_file_path = '/Volumes/universidad_eia/default/isis/token_HF.txt'\n",
        "\n",
        "with open(token_file_path, 'r') as file:\n",
        "    token = file.read().strip()\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "3021b3c0-9ecf-4242-b784-212091aa4bec",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "g7_tyQVNi-Tc"
      },
      "source": [
        "##Generar embeddings para cada documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "59e40061-e453-4c71-8f35-9474be37b5bf",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "6A2BvTRci-Tc",
        "outputId": "4950766e-5f13-4a19-a084-69f10518e24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-10 23:27:40.775256: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a962d067-8012-4044-94a5-dd79776734f4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "EmQYoMuti-Tc",
        "outputId": "bc969f4c-f469-4cec-843e-cad1acfe487f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_id = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModel.from_pretrained(model_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7e62ea50-6ed8-4922-8944-6621b68338de",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "eHYQNtb4i-Td"
      },
      "outputs": [],
      "source": [
        "def embed_text(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "  with torch.no_grad():\n",
        "    embeddings = model(**inputs).pooler_output\n",
        "    #embeddings = model(**inputs).last_hidden_state[:, 0, :]\n",
        "  return embeddings.squeeze().numpy()\n",
        "  #return embeddings.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d9f527b7-fa0f-4ced-8a96-502ed82d14b8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "I1owvQPzi-Td"
      },
      "outputs": [],
      "source": [
        "embeddings_documents = [embed_text(doc) for doc in documents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "77df99e9-ae22-4099-b9d7-ccf29afcf97d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gO5S1Q9ji-Td",
        "outputId": "abe30583-be12-4dbf-a5b0-43159c2883a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 11,
          "metadata": {}
        }
      ],
      "source": [
        "len(embeddings_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "94fe4dd2-4140-482d-9af5-6ca908363936",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "u7cp0wMui-Td",
        "outputId": "83fd281a-09a5-4cdf-ea66-525581eb877e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "execution_count": 12,
          "metadata": {}
        }
      ],
      "source": [
        "embeddings_documents[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c30cd050-4e33-4c3c-ab3a-a1572a13e97e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "cozZmqpAi-Td"
      },
      "source": [
        "##Indexar los embedding\n",
        "\n",
        "Vamos a usar FAISS (Facebook AI Similarity Search) para indexar los embedding.\n",
        "FAISS es una biblioteca de código abierto desarrollada por Facebook para realizar búsquedas de similitud de vectores de manera rápida y eficiente.\n",
        "Utilizaresmos la distancia Euclidiana(L2) para calcular las distancias enre vectores. Este tipo de índice es eficiente para búsquedas rápídas en conjuntos pequeños o medianaos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ee7e78a5-77d9-4bb3-bf79-803b84ed65e4",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "qmxO-L_2i-Td"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5f8dedc9-32ba-4638-9b56-0145aded521a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "CrjYEqigi-Te"
      },
      "outputs": [],
      "source": [
        "dimension = model.config.hidden_size\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings_documents))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "e6356657-7103-4060-84d8-696b1238db0a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "1MQ4ayr-i-Te"
      },
      "source": [
        "# Recuperar los documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "e7f4b709-5d30-42c8-ac80-ea6dddc553d0",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "W9RcEpSOi-Te"
      },
      "outputs": [],
      "source": [
        "def search(query, top_k=2):\n",
        "  query_embedding = embed_text(query).reshape(1, -1)\n",
        "  _, indices = index.search(query_embedding, top_k)\n",
        "  return [documents[i] for i in indices[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "49e06f4b-df13-4570-bc68-d69a619a0f99",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "NEq2n1Uri-Te"
      },
      "source": [
        "## Generar respuesta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b75762d1-d8ba-4a10-8105-bec4e02b4f2d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "ABiFOBuji-Te",
        "outputId": "6ab8c2c8-603c-4a05-cea2-56dbcd872fc4",
        "colab": {
          "referenced_widgets": [
            "dc79bafa0310487088454e4f2c687627",
            "d108c9affa884f86bf5dc270f3dddc21",
            "c54c47e44e474b3488fc055214f2307b",
            "06a8ce2b19544241ac6123335e77c52c",
            "e2a64081d84741729f915ed1c42cc663"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc79bafa0310487088454e4f2c687627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/453 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d108c9affa884f86bf5dc270f3dddc21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c54c47e44e474b3488fc055214f2307b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06a8ce2b19544241ac6123335e77c52c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2a64081d84741729f915ed1c42cc663",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "qa_tokenizer = AutoTokenizer.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d62e6632-2929-4a1c-8172-cc5e78bc37ca",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "A1Wi1P-Zi-Te",
        "outputId": "b4f89698-67e3-4faa-9512-5ca0b6c8647b",
        "colab": {
          "referenced_widgets": [
            "867e840035da4f23be876e2468f57c0a",
            "534f350e97e244ecaea47ddaaea58b58",
            "47b08803cd3f436d94982016667aa0a3",
            "ab39a6f6a54b4adea00cb8091c3a2e84",
            "be1da47626b14420abfa19c5c0140556",
            "6fda14125e3e40f1acdce7e5ac9f20ac",
            "1d17173cbfbf4ba9a3e894ba59d44a58"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "867e840035da4f23be876e2468f57c0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "534f350e97e244ecaea47ddaaea58b58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/858k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47b08803cd3f436d94982016667aa0a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/516k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab39a6f6a54b4adea00cb8091c3a2e84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be1da47626b14420abfa19c5c0140556",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fda14125e3e40f1acdce7e5ac9f20ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/736 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d17173cbfbf4ba9a3e894ba59d44a58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "qa_tokenizer = AutoTokenizer.from_pretrained(\"jamarju/roberta-large-bne-squad-2.0-es\")\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"jamarju/roberta-large-bne-squad-2.0-es\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "76590b00-b4de-42e7-a9a6-0d2c9c424422",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "qCMg0ou-i-Te"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question, context):\n",
        "  prompt = f\"Pregunta: {question}\\nContexto: {context}\\nRespuesta:\"\n",
        "  try:\n",
        "    inputs = qa_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
        "    outputs = qa_model.generate(**inputs, max_new_tokens=50, pad_token_id=qa_tokenizer.eos_token_id)\n",
        "    return qa_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  except Exception as e:\n",
        "    print(\"Error during generation:\", e)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "70118b75-4746-4b22-93af-a10671eb0336",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "zA4BVj5Fi-Tf"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "337c04e1-4e21-4f41-9fef-2ee6b35fc861",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-00KUpFfi-Tf"
      },
      "outputs": [],
      "source": [
        "qa_model = pipeline(\"question-answering\", \"jamarju/roberta-large-bne-squad-2.0-es\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9d09b035-b66c-46c4-9c36-6f9c6bed1a43",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "C0osTl4Mi-Tf",
        "outputId": "65a6148c-4d7e-4932-c754-f9d41b844632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nStuart J. Russell y Peter Norvig diferencian varios tipos de inteligencia artificial:\\n\\nLos sistemas que piensan como humanos: Estos sistemas tratan de emular el pensamiento humano; por ejemplo, las redes neuronales artificiales. La automatización de actividades que vinculamos con procesos de pensamiento humano, actividades como la toma de decisiones, resolución de problemas y aprendizaje.\\nLos sistemas que actúan como humanos: Estos sistemas tratan de actuar como humanos; es decir, imitan el comportamiento humano; por ejemplo, la robótica (El estudio de cómo lograr que los computadores realicen tareas que, por el momento, los humanos hacen mejor).\\nLos sistemas que piensan racionalmente: Es decir, con lógica (idealmente), tratan de imitar el pensamiento racional del ser humano; por ejemplo, los sistemas expertos, (el estudio de los cálculos que hacen posible percibir, razonar y actuar).\\nLos sistemas que actúan racionalmente: Tratan de emular de forma racional el comportamiento humano; por ejemplo, los agentes inteligentes, que está relacionado con conductas inteligentes en artefactos.23\\u200b\\nInteligencia artificial generativa\\nArtículo principal: Inteligencia artificial generativa\\nLa inteligencia artificial generativa es un tipo de sistema de inteligencia artificial capaz de generar texto, imágenes u otros medios en respuesta a comandos.24\\u200b Los modelos de IA generativa aprenden los patrones y la estructura de sus datos de entrenamiento de entrada y luego generan nuevos datos que tienen características similares.\\n\\nLos sistemas de IA generativa notables incluyen ChatGPT (y su variante Microsoft Copilot), un bot conversacional creado por OpenAI usando sus modelos de lenguaje grande fundacionales GPT-3 y GPT-4;\\u200b y Gemini (anteriormente llamado Bard), un bot conversacional creado por Google usando el modelo de lenguaje Gemini. Otros modelos generativos de IA incluyen sistemas de arte de inteligencia artificial como Stable Diffusion, Midjourney y DALL-E.\\n\\nInteligencia artificial fuerte\\nArtículo principal: Inteligencia artificial fuerte\\nLa Inteligencia artificial fuerte (IGA) es un tipo hipotético de inteligencia artificial que iguala o excede la inteligencia humana promedio.\\u200b Si se hiciera realidad, una IGA podría aprender a realizar cualquier tarea intelectual que los seres humanos o los animales puedan llevar a cabo.\\u200b\\u200b Alternativamente, la IGA se ha definido como un sistema autónomo que supera las capacidades humanas en la mayoría de las tareas económicamente valiosas.\\n\\nAlgunos sostienen que podría ser posible en años o décadas; otros, que podría tardar un siglo o más; y una minoría cree que quizá nunca se consiga.\\u200b Existe un debate sobre la definición exacta de IGA y sobre si los grandes modelos de lenguaje (LLM) modernos, como el GPT-4, son formas tempranas pero incompletas de IGA.\\n\\nInteligencia artificial explicable\\nArtículo principal: Inteligencia artificial explicable\\nLa inteligencia artificial explicable se refiere a métodos y técnicas en la aplicación de tecnología de inteligencia artificial por los que el ser humano es capaz de comprender las decisiones y predicciones realizadas por la inteligencia artificial.\\n\\nInteligencia artificial amigable\\nArtículo principal: Inteligencia artificial amigable\\nLa inteligencia artificial amigable es una IA fuerte e hipotética que puede tener un efecto positivo más que uno negativo sobre la humanidad. \\'Amigable\\' es usado en este contexto como terminología técnica y escoge agentes que son seguros y útiles, no necesariamente aquellos que son \"amigables\" en el sentido coloquial. El concepto es invocado principalmente en el contexto de discusiones de agentes artificiales de auto-mejora recursiva que rápidamente explota en inteligencia, con el argumento de que esta tecnología hipotética pudiera tener una larga, rápida y difícil tarea de controlar el impacto en la sociedad humana.\\n\\nInteligencia artificial multimodal\\nArtículo principal: Inteligencia artificial multimodal\\nLa inteligencia artificial multimodal es un tipo de inteligencia artificial que puede procesar e integrar datos de diferentes modalidades, como texto, imágenes, audio y video, para obtener una comprensión más completa y contextualizada de una situación. La inteligencia artificial multimodal se inspira en la forma en que los humanos usan varios sentidos para percibir e interactuar con el mundo, y ofrece una forma más natural e intuitiva de comunicarse con la tecnología.\\n\\nInteligencia artificial cuántica\\nArtículo principal: Inteligencia Artificial Cuántica\\nLa inteligencia artificial Cuántica es un campo interdisciplinar que se enfoca en construir algoritmos cuánticos para mejorar las tareas computacionales dentro de la IA, incluyendo subcampos como el aprendizaje automático.\\u200b Existen evidencias que muestran una posible ventaja cuadrática cuántica en operaciones fundamentales de la IA.\\n \\nLa inteligencia artificial (IA), en el contexto de las ciencias de la computación, es una disciplina y un conjunto de capacidades cognoscitivas e intelectuales expresadas por sistemas informáticos o combinaciones de algoritmos cuyo propósito es la creación de máquinas que imiten la inteligencia humana para realizar tareas, y que pueden mejorar conforme recopilen información.1\\u200b2\\u200b Se hizo presente poco después de la Segunda Guerra Mundial con el desarrollo de la «prueba de Turing», mientras que la locución fue acuñada en 1956 por el informático John McCarthy en la Conferencia de Dartmouth.\\n\\nEn la actualidad, la inteligencia artificial abarca una gran variedad de subcampos. Éstos van desde áreas de propósito general, aprendizaje y percepción, a otras más específicas como el reconocimiento de voz, el juego de ajedrez, la demostración de teoremas matemáticos, la escritura de poesía y el diagnóstico de enfermedades. La inteligencia artificial sintetiza y automatiza tareas que en principio son intelectuales y, por lo tanto, es potencialmente relevante para cualquier ámbito de actividades intelectuales humanas. En este sentido, es un campo genuinamente universal.\\n\\nLa arquitectura de las inteligencias artificiales y los procesos por los cuales aprenden, se mejoran y se implementan en algún área de interés varía según el enfoque de utilidad que se les quiera dar, pero de manera general, estos van desde la ejecución de sencillos algoritmos hasta la interconexión de complejas redes neuronales artificiales que intentan replicar los circuitos neuronales del cerebro humano y que aprenden mediante diferentes modelos de aprendizaje tales como el aprendizaje automático, el aprendizaje por refuerzo, el aprendizaje profundo y el aprendizaje supervisado.\\n\\nPor otro lado, el desarrollo y aplicación de la inteligencia artificial en muchos aspectos de la vida cotidiana también ha propiciado la creación de nuevos campos de estudio como la roboética y la ética de las máquinas que abordan aspectos relacionados con la ética en la inteligencia artificial y que se encargan de analizar cómo los avances en este tipo de tecnologías impactarían en diversos ámbitos de la vida, así como el manejo responsable y ético que se les debería dar a los mismos, además de establecer cuál debería ser la manera correcta de proceder de las máquinas y las reglas que deberían cumplir.\\n\\nEn cuanto a su clasificación, tradicionalmente se divide a la inteligencia artificial en inteligencia artificial débil, la cual es la única que existe en la actualidad y que se ocupa de realizar tareas específicas, e inteligencia artificial general, que sería una IA que excediese las capacidades humanas. Algunos expertos creen que si alguna vez se alcanza este nivel, se podría dar lugar a la aparición de una singularidad tecnológica, es decir, una entidad tecnológica superior que se mejoraría a sí misma constantemente, volviéndose incontrolable para los humanos, dando pie a teorías como el basilisco de Roko.\\n\\nAlgunas de las inteligencias artificiales más conocidas y utilizadas en la actualidad alrededor del mundo incluyen inteligencia artificial en el campo de la salud, asistentes virtuales como Alexa, el asistente de Google o Siri, traductores automáticos como el traductor de Google y DeepL, sistemas de recomendación como el de la plataforma digital de YouTube, motores de ajedrez y otros juegos como Stockfish y AlphaZero, chatbots como ChatGPT, creadores de arte de inteligencia artificial como Midjourney, Dall-e, Leonardo y Stable Diffusion, e incluso la conducción de vehículos autónomos como Tesla Autopilot.\\n'"
            ]
          },
          "execution_count": 34,
          "metadata": {}
        }
      ],
      "source": [
        "question = \"¿Qué es la inteligencia artificial?\"\n",
        "relevant_docs = search(question, top_k=2)\n",
        "combined_context = \" \".join(relevant_docs)\n",
        "combined_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "20417ef8-60fc-48e8-83ae-0c7cb6b23785",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Z6nMXSUEi-Tf",
        "outputId": "43a830ce-481e-4aed-993a-20dee782c51b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.6516901850700378,\n",
              " 'start': 2103,\n",
              " 'end': 2200,\n",
              " 'answer': 'un tipo hipotético de inteligencia artificial que iguala o excede la inteligencia humana promedio'}"
            ]
          },
          "execution_count": 64,
          "metadata": {}
        }
      ],
      "source": [
        "qa_model(question=question, context=combined_context,num_return_sequences=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6748744a-9354-409a-955e-6e1c07c1f679",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "9uCAk8gmi-Tf"
      },
      "outputs": [],
      "source": [
        "def generate_answers(question, context):\n",
        "  prompt = f\"Pregunta: {question}\\nContexto: {context}\\nRespuesta:\"\n",
        "  result = qa_model(question=question, context=context,num_return_sequences=1, max_new_tokens=1024)\n",
        "  return result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "98452f80-2bd5-41c5-b030-6ff895b2f91d",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "-9Wdk09Li-Tf"
      },
      "outputs": [],
      "source": [
        "def rag_answer(question):\n",
        "  # Recuperar contexto relevante\n",
        "  relevant_docs = search(question, top_k=2)\n",
        "  combined_context = \" \".join(relevant_docs)\n",
        "  # Generar respuesta\n",
        "  answer = generate_answers(question, combined_context)\n",
        "  return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "68f3570c-1896-4edf-8a13-a04ca15832b1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "oKJD3U5ii-Tf",
        "outputId": "21d2d13e-24cc-4f79-913c-77b298763f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "un tipo hipotético de inteligencia artificial que iguala o excede la inteligencia humana promedio\n"
          ]
        }
      ],
      "source": [
        "question = \"¿Qué es la inteligencia artificial?\"\n",
        "print(rag_answer(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "af24f7d2-758f-421b-9902-9e1cf21896af",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "aRQCXiL8i-Tg",
        "outputId": "77ac4159-a42e-4096-8834-14f6d7865c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "salud\n"
          ]
        }
      ],
      "source": [
        "question = \"¿En qué campos se utiliza inteligencia artificial?\"\n",
        "print(rag_answer(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "2302d6e1-a5c2-4e2d-8b3e-63cf107dba09",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "W3BD3QZIi-Tg",
        "outputId": "703ac7db-095f-42cd-b70f-f23a48b8fde4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inteligencia artificial débil\n"
          ]
        }
      ],
      "source": [
        "question = \"¿Qué tipos de Inteligencia Artificial existen?\"\n",
        "print(rag_answer(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "71c12b16-f630-40c3-9838-4aca47a2e55b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "osdcvyKGi-Tg"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "7d2137e9-a42b-4a8a-b4f9-a29fa6fbbbb6",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "6hjb8Axti-Tg",
        "outputId": "22f9e003-a41c-498b-d8fa-561192bb9752",
        "colab": {
          "referenced_widgets": [
            "bf7c563910f3444791d1ba7307b3f9f3",
            "a880336f2d9b4fedbb23d37b299813c0",
            "5949986e8d7f40bc9aa6fb5b5071b86e",
            "5146bf44036945b0bff5a0324ca3fa5b",
            "74705cbecfef47d986e35a6e4e06102a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf7c563910f3444791d1ba7307b3f9f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/588 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a880336f2d9b4fedbb23d37b299813c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForQuestionAnswering were not initialized from the model checkpoint at vgaraujov/t5-base-spanish and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5949986e8d7f40bc9aa6fb5b5071b86e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5146bf44036945b0bff5a0324ca3fa5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/837k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74705cbecfef47d986e35a6e4e06102a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline(\"question-answering\", model=\"vgaraujov/t5-base-spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "20549c69-d137-42b4-a9a3-2c46c06192f9",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "rKfg3ye7i-Tg"
      },
      "outputs": [],
      "source": [
        "qa_model = pipeline(\"question-answering\", \"jamarju/roberta-large-bne-squad-2.0-es\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "667bcc16-a818-45db-921b-fb26d8c89da1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "68r8tOJZi-Th",
        "outputId": "437ba344-a3bd-45e0-88b8-f3d380137c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inteligencia artificial débil\n"
          ]
        }
      ],
      "source": [
        "question = \"¿Qué tipos de Inteligencia Artificial existen?\"\n",
        "print(rag_answer(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "118b4671-0679-45e2-abe0-d592e8d9a454",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "SGofZoMJi-Th",
        "outputId": "1856bbe5-732a-4f58-bec9-a1267240fb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sistemas que llevan a cabo tareas consideradas inteligentes\",\n"
          ]
        }
      ],
      "source": [
        "question = \"¿Qué es la Inteligencia Artificial?\"\n",
        "print(rag_answer(question))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f14e5fbc-0132-4287-bac3-3b322a97df2a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "k243GRp5i-Th"
      },
      "source": [
        "## Utilizar otro ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "dcaf02fd-e389-4de1-a6b4-4d87a16e775e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "OPlfeM21i-Ti"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "from transformers import pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "700cc944-147e-4a35-bb66-db1410a74714",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "PtbNYDs1i-Ti"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"timpal0l/mdeberta-v3-base-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6493eb88-c922-4b72-bc33-342e834c44b8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "Jl0ylAZni-Ti"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "documents_vectorizer = vectorizer.fit_transform(documents).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "caa09c01-5eac-47e0-9529-57c7a660b77c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "gWIrtJjhi-Ti"
      },
      "outputs": [],
      "source": [
        "dimension = documents_vectorizer.shape[1]  # Dimensión del espacio vectorial\n",
        "index = faiss.IndexFlatL2(dimension)  # Índice de búsqueda usando L2 (distancia euclidiana)\n",
        "index.add(np.array(documents_vectorizer, dtype=np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c01e0d7a-a187-492b-94c7-6c81312f1e62",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "dabCOXfBi-Ti"
      },
      "outputs": [],
      "source": [
        "def retrieve_document(query, k=1):\n",
        "  # Vectorizar la pregunta\n",
        "  query_vectorizer = vectorizer.transform([query]).toarray()\n",
        "  # Buscar los k documentos más relevantes\n",
        "  _, indexes = index.search(np.array(query_vectorizer, dtype=np.float32), k)\n",
        "  return [documents[i] for i in indexes[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a865d377-8208-492b-bd5e-21bb6594f92b",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "jPwxoBADi-Ti"
      },
      "outputs": [],
      "source": [
        "def rag(query):\n",
        "  # Recuperar el documento relevante\n",
        "  relevant_documents = retrieve_document(query)\n",
        "  context = relevant_documents[0]  # Usar el primer documento como contexto\n",
        "\n",
        "  detailed_query = f\"{query}. Por favor, da una respuesta completa y detallada.\"\n",
        "  # Tokenizar la pregunta y el contexto\n",
        "  inputs = tokenizer(detailed_query, context, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "  # Obtener la respuesta\n",
        "  with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "      start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "  # Obtener las posiciones de inicio y fin de la respuesta\n",
        "  start_index = torch.argmax(start_scores)\n",
        "  end_index = torch.argmax(end_scores) + 1  # +1 porque es inclusivo\n",
        "\n",
        "  # Convertir los índices a texto\n",
        "  answer_tokens = inputs.input_ids[0][start_index:end_index]\n",
        "  answer = tokenizer.decode(answer_tokens)\n",
        "  return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "03de6884-ed66-466a-a717-b1afa9fecbed",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "GmokoxFzi-Ti",
        "outputId": "ecb03607-c56f-40db-f8e1-5b0cde50c510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pregunta: ¿Qué es la inteligencia artificial?\nRespuesta: un tipo de sistema de inteligencia artificial capaz de generar texto, imágenes u otros medios en respuesta a comandos\n"
          ]
        }
      ],
      "source": [
        "pregunta = \"¿Qué es la inteligencia artificial?\"\n",
        "respuesta = rag(pregunta)\n",
        "\n",
        "print(f\"Pregunta: {pregunta}\")\n",
        "print(f\"Respuesta: {respuesta}\")"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "client": "1"
      },
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "Ejemplo_RAG",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}